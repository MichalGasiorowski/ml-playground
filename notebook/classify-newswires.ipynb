{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history_dict):\n",
    "    \n",
    "    acc = history_dict['binary_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.clf() # clear figure\n",
    "    acc_values = history_dict['binary_accuracy']\n",
    "    val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyperparameters(parameters):\n",
    "    loss_function = parameters['loss_function']\n",
    "    dense_layer_count = parameters['dense_layer_count']\n",
    "    hidden_units = parameters['hidden_units']\n",
    "    activation_function = parameters['activation_function']\n",
    "    batch_size = parameters.get('batch_size') or 512\n",
    "    lr = parameters.get('lr') or 0.001\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "    for _ in range(dense_layer_count - 1):        \n",
    "        model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=lr), \n",
    "                  loss=loss_function, metrics=[metrics.binary_accuracy])   \n",
    "    \n",
    "    history = model.fit(partial_x_train, partial_y_train,\n",
    "                   epochs=10, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "    \n",
    "    history_dict = history.history\n",
    "    results = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print(results)\n",
    "    plot_accuracy(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 2246\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in\n",
    "train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "#one_hot_train_labels = to_categorical(train_labels)\n",
    "#one_hot_test_labels = to_categorical(test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

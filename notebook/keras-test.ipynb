{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]\n",
    "train_labels[0]\n",
    "\n",
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "[reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuring optimzers\n",
    "from tensorflow.keras import optimizers\n",
    "# custom losses and metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "loss=losses.binary_crossentropy,\n",
    "metrics=[metrics.binary_accuracy])              \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train,\n",
    "                   epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "history_dict[]\n",
    "len(history_dict.keys().g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss') # blue dot\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') # blue\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf() # clear figure\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history_dict):\n",
    "    \n",
    "    acc = history_dict['binary_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.clf() # clear figure\n",
    "    acc_values = history_dict['binary_accuracy']\n",
    "    val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting -> validation accuracy doesn't improve after 4 epoch\n",
    "# traing it for 4 epochs\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a trained network to generate predictions on new data\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments\n",
    "# use 3 layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), \n",
    "              loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])   \n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train,\n",
    "                   epochs=20, batch_size=512, validation_data=(x_val, y_val))\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "#results = model.evaluate(x_test, y_test)\n",
    "\n",
    "#print(results)\n",
    "history_dict = history.history\n",
    "\n",
    "plot_accuracy(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyperparameters(parameters):\n",
    "    loss_function = parameters['loss_function']\n",
    "    dense_layer_count = parameters['dense_layer_count']\n",
    "    hidden_units = parameters['hidden_units']\n",
    "    activation_function = parameters['activation_function']\n",
    "    batch_size = parameters.get('batch_size') or 512\n",
    "    lr = parameters.get('lr') or 0.001\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "    for _ in range(dense_layer_count - 1):        \n",
    "        model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=lr), \n",
    "                  loss=loss_function, metrics=[metrics.binary_accuracy])   \n",
    "    \n",
    "    history = model.fit(partial_x_train, partial_y_train,\n",
    "                   epochs=10, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "    \n",
    "    history_dict = history.history\n",
    "    results = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print(results)\n",
    "    plot_accuracy(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'loss_function' : 'binary_crossentropy', 'dense_layer_count':6, \n",
    "              'hidden_units' : 256, 'activation_function': 'relu', 'batch_size': 512, 'lr': 0.01}\n",
    "test_hyperparameters(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = {'loss_function' : 'mse', 'dense_layer_count':3, 'hidden_units' : 16, 'activation_function': 'relu'}\n",
    "print(aa['loss_function'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:39:44.015641Z",
     "start_time": "2020-05-20T22:39:40.069585Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: jupyterlab-git 0.10.1 has requirement nbdime<2.0.0,>=1.1.0, but you'll have nbdime 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-beam 2.22.0 has requirement httplib2<0.18.0,>=0.8, but you'll have httplib2 0.18.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-beam 2.22.0 has requirement mock<3.0.0,>=1.0.1, but you'll have mock 4.0.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle\n",
    "#!pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n",
      "-rw------- 1 jupyter jupyter 73 Aug 12 15:32 /home/jupyter/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!ls -l ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T21:02:56.075438Z",
     "start_time": "2020-05-17T21:02:55.972412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './../data': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "data_base_path = os.path.join(os.path.curdir, '../data')\n",
    "titanic_base_path = os.path.join(data_base_path, 'titanic')\n",
    "\n",
    "!ls $data_base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:37:37.832561Z",
     "start_time": "2020-05-20T22:37:37.826565Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_from_kaggle(dataset=\"titanic\", data_base_path=data_base_path):\n",
    "    data_path = os.path.join(os.path.curdir, f\"{data_base_path}/{dataset}\")\n",
    "    !kaggle competitions download -c $dataset --path $data_path --force\n",
    "    !unzip -o $data_path/titanic.zip -d $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:38:01.443871Z",
     "start_time": "2020-05-20T22:38:00.330969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to ././../data/titanic\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 24.7MB/s]\n",
      "Archive:  ././../data/titanic/titanic.zip\n",
      "  inflating: ././../data/titanic/gender_submission.csv  \n",
      "  inflating: ././../data/titanic/test.csv  \n",
      "  inflating: ././../data/titanic/train.csv  \n"
     ]
    }
   ],
   "source": [
    "load_data_from_kaggle(dataset=\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T23:48:52.908421Z",
     "start_time": "2020-05-23T23:48:52.904397Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_titanic_dateset(titanic_path=titanic_base_path):\n",
    "    gender_submission_csv_path = os.path.join(titanic_path, \"gender_submission.csv\")\n",
    "    train_csv_path = os.path.join(titanic_path, \"train.csv\")\n",
    "    test_csv_path = os.path.join(titanic_path, \"test.csv\")\n",
    "    return pd.read_csv(gender_submission_csv_path), pd.read_csv(train_csv_path), pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T23:48:55.753459Z",
     "start_time": "2020-05-23T23:48:55.702462Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_sub_df, train_df, test_df = load_titanic_dateset(titanic_path=titanic_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T23:52:16.597837Z",
     "start_time": "2020-05-23T23:52:16.578833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.3</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male 22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female 38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female 26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female 35.0      1   \n",
       "4                           Allen, Mr. William Henry    male 35.0      0   \n",
       "\n",
       "   Parch            Ticket  Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2   NaN        S  \n",
       "1      0          PC 17599  71.3   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9   NaN        S  \n",
       "3      0            113803  53.1  C123        S  \n",
       "4      0            373450   8.1   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(list(train_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name is: PassengerId and it value is: 891    1\n",
      "293    1\n",
      "304    1\n",
      "303    1\n",
      "302    1\n",
      "      ..\n",
      "591    1\n",
      "590    1\n",
      "589    1\n",
      "588    1\n",
      "1      1\n",
      "Name: PassengerId, Length: 891, dtype: int64\n",
      "\n",
      "Column name is: Survived and it value is: 0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "Column name is: Pclass and it value is: 3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "Column name is: Name and it value is: Taylor, Mr. Elmer Zebley            1\n",
      "Silverthorne, Mr. Spencer Victor    1\n",
      "Lievens, Mr. Rene Aime              1\n",
      "Zabour, Miss. Thamine               1\n",
      "Perkin, Mr. John Henry              1\n",
      "                                   ..\n",
      "Molson, Mr. Harry Markland          1\n",
      "Bourke, Mr. John                    1\n",
      "Carlsson, Mr. Frans Olof            1\n",
      "Barbara, Mrs. (Catherine David)     1\n",
      "Nysten, Miss. Anna Sofia            1\n",
      "Name: Name, Length: 891, dtype: int64\n",
      "\n",
      "Column name is: Sex and it value is: male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "Column name is: Age and it value is: 24.0    30\n",
      "22.0    27\n",
      "18.0    26\n",
      "19.0    25\n",
      "30.0    25\n",
      "        ..\n",
      "55.5     1\n",
      "70.5     1\n",
      "66.0     1\n",
      "23.5     1\n",
      "0.4      1\n",
      "Name: Age, Length: 88, dtype: int64\n",
      "\n",
      "Column name is: SibSp and it value is: 0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "\n",
      "Column name is: Parch and it value is: 0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "\n",
      "Column name is: Ticket and it value is: 347082             7\n",
      "1601               7\n",
      "CA. 2343           7\n",
      "3101295            6\n",
      "347088             6\n",
      "                  ..\n",
      "A/S 2816           1\n",
      "349231             1\n",
      "371060             1\n",
      "SC/AH Basle 541    1\n",
      "349236             1\n",
      "Name: Ticket, Length: 681, dtype: int64\n",
      "\n",
      "Column name is: Fare and it value is: 8.1     43\n",
      "13.0    42\n",
      "7.9     38\n",
      "7.8     34\n",
      "26.0    31\n",
      "        ..\n",
      "8.5      1\n",
      "9.8      1\n",
      "8.4      1\n",
      "14.1     1\n",
      "17.4     1\n",
      "Name: Fare, Length: 248, dtype: int64\n",
      "\n",
      "Column name is: Cabin and it value is: B96 B98        4\n",
      "G6             4\n",
      "C23 C25 C27    4\n",
      "C22 C26        3\n",
      "F33            3\n",
      "              ..\n",
      "C118           1\n",
      "E36            1\n",
      "D50            1\n",
      "C54            1\n",
      "C45            1\n",
      "Name: Cabin, Length: 147, dtype: int64\n",
      "\n",
      "Column name is: Embarked and it value is: S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_df.apply(pd.value_counts)\n",
    "\n",
    "for i in train_df.columns:\n",
    "    x = train_df[i].value_counts()\n",
    "    print(\"Column name is:\",i,\"and it value is:\",x)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.2042079685746"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = None\n",
    "most_embarked_from = None\n",
    "train_fare_mean = None\n",
    "train_fare_std = None\n",
    "feat_bins = {}\n",
    "\n",
    "def drop_columns(df):\n",
    "    df.drop(\"Name\", axis=1, inplace=True)\n",
    "    df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "    df.drop(\"Ticket\", axis=1, inplace=True)\n",
    "    df.drop(\"Cabin\", axis=1, inplace=True)\n",
    "    df.drop(\"Sex_female\", axis=1, inplace=True)\n",
    "    df.drop('SibSp', axis=1, inplace=True)\n",
    "    df.drop('Parch', axis=1, inplace=True)\n",
    "    df.drop('Age', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    copy_df = df.copy()\n",
    "    \n",
    "    global median_age\n",
    "    global most_embarked_from\n",
    "    global train_fare_mean\n",
    "    global train_fare_std\n",
    "    \n",
    "    median_age = median_age or copy_df[\"Age\"].median(skipna=True)\n",
    "    most_embarked_from = most_embarked_from or copy_df[\"Embarked\"].value_counts().idxmax()\n",
    "    train_fare_mean = train_fare_mean or copy_df[\"Fare\"].mean(skipna=True)\n",
    "    train_fare_std = train_fare_std or copy_df[\"Fare\"].std(skipna=True)\n",
    "    \n",
    "    copy_df[\"Age\"] = copy_df[\"Age\"].fillna(median_age)\n",
    "    copy_df[\"Embarked\"] = copy_df[\"Embarked\"].fillna(most_embarked_from)\n",
    "    copy_df[\"Fare\"] = (copy_df[\"Fare\"] - train_fare_mean) / train_fare_std\n",
    "    \n",
    "    return copy_df\n",
    "    \n",
    "def create_categorical(df):\n",
    "    copy_df = pd.get_dummies(df, columns=[\"Pclass\", \"Embarked\", \"Title\", \"Sex\"])\n",
    "\n",
    "    return copy_df\n",
    "\n",
    "def add_engineered(df):\n",
    "    df['TravelAlone'] = np.where((df[\"SibSp\"] + df[\"Parch\"])>0, 0, 1)\n",
    "    df['TravelAlone'] = df['TravelAlone'].astype('uint8')\n",
    "    \n",
    "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    \n",
    "    df['Title'] = df['Title'].replace(['Mlle','Mme','Ms'], 'Miss') # Mlle = Mademoiselle\n",
    "    \n",
    "    df['Family'] = df['Parch'] + df['SibSp']\n",
    "    \n",
    "    return df\n",
    "def create_bins(df):\n",
    "    df = df\n",
    "    for j in ['Age']:\n",
    "        df = bin_maker(df=df, col_name=j, num_bins=10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def bin_maker(df, col_name, num_bins):\n",
    "    global feat_bins\n",
    "    \n",
    "    '''Input dataframe, the name of the column and the number of qcut bins'''\n",
    "    \n",
    "    if col_name not in feat_bins:    \n",
    "        df[f'{col_name}Bins'], feat_bins_ret = pd.qcut(df[col_name], q=num_bins, retbins=True, labels=False, duplicates='drop')\n",
    "        feat_bins[col_name] = feat_bins_ret\n",
    "    else:\n",
    "        df[f'{col_name}Bins'] = pd.cut(df[col_name], bins=feat_bins[col_name], labels=False, duplicates='drop')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def change_types(df):\n",
    "    df['TravelAlone'] = df['TravelAlone'].astype('uint8')\n",
    "    if 'Survived' in df.columns:\n",
    "        df['Survived'] = df['Survived'].astype('uint8')\n",
    "        \n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    copy_df = df.copy()\n",
    "    \n",
    "    copy_df = fill_missing_values(copy_df)\n",
    "    copy_df = add_engineered(copy_df)\n",
    "    copy_df = create_bins(copy_df)\n",
    "    copy_df = create_categorical(copy_df)\n",
    "    copy_df = drop_columns(copy_df)\n",
    "    copy_df = change_types(copy_df)\n",
    "    \n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean = clean_data(train_df)\n",
    "test_df_clean = clean_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Fare</th>\n",
       "      <th>TravelAlone</th>\n",
       "      <th>Family</th>\n",
       "      <th>AgeBins</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Fare  TravelAlone  Family  AgeBins  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0         0  -0.5            0       1        2         0         0         1   \n",
       "1         1   0.8            0       1        5         1         0         0   \n",
       "2         1  -0.5            1       0        3         0         0         1   \n",
       "3         1   0.4            0       1        5         1         0         0   \n",
       "4         0  -0.5            1       0        5         0         0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0           0           0           1             0           0         1   \n",
       "1           1           0           0             0           0         0   \n",
       "2           0           0           1             0           1         0   \n",
       "3           0           0           1             0           0         0   \n",
       "4           0           0           1             0           0         1   \n",
       "\n",
       "   Title_Mrs  Title_Rare  Sex_male  \n",
       "0          0           0         1  \n",
       "1          1           0         0  \n",
       "2          0           0         0  \n",
       "3          1           0         0  \n",
       "4          0           0         1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Survived      891 non-null    uint8  \n",
      " 1   Fare          891 non-null    float64\n",
      " 2   TravelAlone   891 non-null    uint8  \n",
      " 3   Family        891 non-null    int64  \n",
      " 4   AgeBins       891 non-null    int64  \n",
      " 5   Pclass_1      891 non-null    uint8  \n",
      " 6   Pclass_2      891 non-null    uint8  \n",
      " 7   Pclass_3      891 non-null    uint8  \n",
      " 8   Embarked_C    891 non-null    uint8  \n",
      " 9   Embarked_Q    891 non-null    uint8  \n",
      " 10  Embarked_S    891 non-null    uint8  \n",
      " 11  Title_Master  891 non-null    uint8  \n",
      " 12  Title_Miss    891 non-null    uint8  \n",
      " 13  Title_Mr      891 non-null    uint8  \n",
      " 14  Title_Mrs     891 non-null    uint8  \n",
      " 15  Title_Rare    891 non-null    uint8  \n",
      " 16  Sex_male      891 non-null    uint8  \n",
      "dtypes: float64(1), int64(2), uint8(14)\n",
      "memory usage: 33.2 KB\n"
     ]
    }
   ],
   "source": [
    "train_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.loc[888:889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "Fare\n",
      "TravelAlone\n",
      "Family\n",
      "AgeBins\n",
      "Pclass_1\n",
      "Pclass_2\n",
      "Pclass_3\n",
      "Embarked_C\n",
      "Embarked_Q\n",
      "Embarked_S\n",
      "Title_Master\n",
      "Title_Miss\n",
      "Title_Mr\n",
      "Title_Mrs\n",
      "Title_Rare\n",
      "Sex_male\n"
     ]
    }
   ],
   "source": [
    "for column in train_df_clean.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Fare', 'TravelAlone', 'Family', 'AgeBins', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare', 'Sex_male'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featcols = {\n",
    "  colname : tf.feature_column.numeric_column(colname) \\\n",
    "    #for colname in 'Age,Fare,Pclass_1,Pclass_2,Pclass_3,Embarked_C,Embarked_Q,Embarked_S,Sex_male,TravelAlone'.split(',')\n",
    "    for colname in train_df_clean.columns if colname != 'Survived'\n",
    "}\n",
    "featcols.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and eval\n",
    "msk = np.random.rand(len(train_df_clean)) < 0.8\n",
    "traindf = train_df_clean[msk]\n",
    "evaldf = train_df_clean[~msk]\n",
    "\n",
    "BATCH_SIZE= 20\n",
    "OUTDIR = '../models'\n",
    "\n",
    "\n",
    "def make_input_fn(df, mode, batch_size = BATCH_SIZE):\n",
    "    global mean_train_fare\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # loop indefinetly\n",
    "        shuffle=True\n",
    "        y = df[\"Survived\"]\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        num_epochs = 1 # one run and it's over\n",
    "        shuffle=False\n",
    "        y = df[\"Survived\"]\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        num_epochs = 1 # one run and it's over\n",
    "        shuffle=False\n",
    "        y = None\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(x = df[list(featcols.keys())],\n",
    "                                                y = y,\n",
    "                                                num_epochs = num_epochs,\n",
    "                                                batch_size = batch_size, \n",
    "                                                shuffle = shuffle)\n",
    "\n",
    "def train_input_fn(df, batch_size=BATCH_SIZE):\n",
    "    return make_input_fn(df, mode=tf.estimator.ModeKeys.TRAIN, batch_size=batch_size)\n",
    "\n",
    "def eval_input_fn(df):\n",
    "    return make_input_fn(df, mode=tf.estimator.ModeKeys.EVAL, batch_size=len(df))\n",
    "\n",
    "def test_input_fn(df):\n",
    "    return make_input_fn(df, mode=tf.estimator.ModeKeys.PREDICT, batch_size=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../models/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6660668, step = 0\n",
      "INFO:tensorflow:global_step/sec: 62.9797\n",
      "INFO:tensorflow:loss = 0.45160708, step = 100 (1.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4117\n",
      "INFO:tensorflow:loss = 0.32501918, step = 200 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9951\n",
      "INFO:tensorflow:loss = 0.5132626, step = 300 (1.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3695\n",
      "INFO:tensorflow:loss = 0.34972164, step = 400 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.7979\n",
      "INFO:tensorflow:loss = 0.4430645, step = 500 (1.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.1287\n",
      "INFO:tensorflow:loss = 0.51011, step = 600 (1.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.742\n",
      "INFO:tensorflow:loss = 0.22204342, step = 700 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.614\n",
      "INFO:tensorflow:loss = 0.3653589, step = 800 (0.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.596\n",
      "INFO:tensorflow:loss = 0.7876481, step = 900 (0.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.507\n",
      "INFO:tensorflow:loss = 0.2296789, step = 1000 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.786\n",
      "INFO:tensorflow:loss = 0.25341088, step = 1100 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.67\n",
      "INFO:tensorflow:loss = 0.43516907, step = 1200 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.178\n",
      "INFO:tensorflow:loss = 0.38371885, step = 1300 (0.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6426\n",
      "INFO:tensorflow:loss = 0.47832718, step = 1400 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.4033\n",
      "INFO:tensorflow:loss = 0.3796633, step = 1500 (1.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.8558\n",
      "INFO:tensorflow:loss = 0.31184515, step = 1600 (0.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.654\n",
      "INFO:tensorflow:loss = 0.21293595, step = 1700 (0.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1414\n",
      "INFO:tensorflow:loss = 0.5357884, step = 1800 (1.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.273\n",
      "INFO:tensorflow:loss = 0.3286025, step = 1900 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.616\n",
      "INFO:tensorflow:loss = 0.2056624, step = 2000 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.843\n",
      "INFO:tensorflow:loss = 0.33997962, step = 2100 (0.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.854\n",
      "INFO:tensorflow:loss = 0.57067406, step = 2200 (1.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.4973\n",
      "INFO:tensorflow:loss = 0.17390387, step = 2300 (1.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.92\n",
      "INFO:tensorflow:loss = 0.5211056, step = 2400 (0.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.935\n",
      "INFO:tensorflow:loss = 0.35820216, step = 2500 (0.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.115\n",
      "INFO:tensorflow:loss = 0.36212343, step = 2600 (0.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1877\n",
      "INFO:tensorflow:loss = 0.37984198, step = 2700 (1.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8636\n",
      "INFO:tensorflow:loss = 0.37982106, step = 2800 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7014\n",
      "INFO:tensorflow:loss = 0.43788892, step = 2900 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.901\n",
      "INFO:tensorflow:loss = 0.5103375, step = 3000 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.251\n",
      "INFO:tensorflow:loss = 0.25313902, step = 3100 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8704\n",
      "INFO:tensorflow:loss = 0.30731648, step = 3200 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8807\n",
      "INFO:tensorflow:loss = 0.24933138, step = 3300 (1.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2776\n",
      "INFO:tensorflow:loss = 0.21860227, step = 3400 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.2382\n",
      "INFO:tensorflow:loss = 0.47247458, step = 3500 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8532\n",
      "INFO:tensorflow:loss = 0.2544037, step = 3600 (1.392 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3630 into ../models/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-08-10T16:06:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/model.ckpt-3630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.85672s\n",
      "INFO:tensorflow:Finished evaluation at 2020-08-10-16:06:26\n",
      "INFO:tensorflow:Saving dict for global step 3630: accuracy = 0.8, accuracy_baseline = 0.6181818, auc = 0.86103326, auc_precision_recall = 0.80644226, average_loss = 0.5798943, global_step = 3630, label/mean = 0.38181818, loss = 0.5798943, precision = 0.7777778, prediction/mean = 0.40393847, recall = 0.6666667\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3630: ../models/model.ckpt-3630\n",
      "INFO:tensorflow:Loss for final step: 0.25935507.\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "estimator = None\n",
    "\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "    myopt = tf.keras.optimizers.Ftrl(learning_rate = 0.01, l1_regularization_strength=0.001) # note the learning rate\n",
    "    #ada_optimizer=tf.compat.v1.train.ProximalAdagradOptimizer(learning_rate=0.1, l1_regularization_strength=0.001)\n",
    "    \n",
    "    adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001 ) # note the learning rate\n",
    "\n",
    "    estimator = tf.estimator.DNNClassifier(\n",
    "                        model_dir = output_dir, \n",
    "                        feature_columns = featcols.values(),\n",
    "                        hidden_units=[1024, 256, 32],\n",
    "                        optimizer = adam_opt,\n",
    "                        dropout=0.2,\n",
    "                        n_classes=NUM_CLASSES)\n",
    "    \n",
    "    #estimator = tf.estimator.DNNClassifier(\n",
    "    #feature_columns=[categorical_feature_a_emb, categorical_feature_b_emb],\n",
    "    #hidden_units=[1024, 512, 256])\n",
    "  \n",
    "    #def my_auc(labels, predictions):\n",
    "    #    auc_metric = tf.keras.metrics.AUC(name=\"my_auc\")\n",
    "    #    auc_metric.update_state(y_true=labels, y_pred=predictions['logistic'])\n",
    "    #    return {'auc': auc_metric}\n",
    "\n",
    "    #estimator = tf.compat.v1.estimator.add_metrics(estimator, rmse)\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn(df = traindf, batch_size = BATCH_SIZE),\n",
    "                                      max_steps = num_train_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn(df = evaldf),\n",
    "                                        steps = None,                                        \n",
    "                                        start_delay_secs = 1, # start evaluating after N seconds\n",
    "                                        throttle_secs = 10  # evaluate every N seconds)\n",
    "                                     )\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "    \n",
    "    return estimator\n",
    "    \n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "estimator = train_and_evaluate(OUTDIR, num_train_steps = (100 * len(traindf)) / BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = estimator.predict(input_fn=test_input_fn(test_df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions: 416\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = [p[\"classes\"] for p in results]\n",
    "print('Number of predictions: {}'.format(len(predicted_classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (418, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = test_df['PassengerId']\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = test_id\n",
    "submission['Survived'] = predicted_classes\n",
    "submission['Survived'] = submission['Survived'].astype(int)\n",
    "\n",
    "print('Submission shape: {}'.format(submission.shape))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('titanic_DNN_submission_1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
